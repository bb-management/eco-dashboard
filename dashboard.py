import streamlit as st
import requests
import pandas as pd
from transformers import pipeline
import time

# Tes cl√©s API ‚Äî √† remplacer par tes vraies cl√©s
FINNHUB_API_KEY = "d1sua1pr01qhe5rc4vj0d1sua1pr01qhe5rc4vjg"
MARKETAUX_API_KEY = "dOdEj91ZiMvnDMFVP9n2hwoz1rMTm7cy3OnjA0Xv"

# Liste de mots cl√©s pour filtrer les articles √©conomiques
KEYWORDS_ECO = [
    "√©conomie", "march√©", "inflation", "banque", "investissement", "bourse",
    "croissance", "emploi", "taux", "finance", "industrie", "PIB", "ch√¥mage",
    "r√©cession", "export", "import", "dette", "tr√©sor", "action", "dividende"
]

# Chargement des mod√®les avec cache pour ne pas recharger √† chaque fois
@st.cache_resource(show_spinner=False)
def load_models():
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    sentiment_analyzer = pipeline("sentiment-analysis")
    translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-fr")
    return summarizer, sentiment_analyzer, translator

summarizer, sentiment_analyzer, translator = load_models()

def translate_text(text):
    # Limiter la longueur sinon erreur max_length
    if len(text) > 512:
        text = text[:512]
    result = translator(text)
    return result[0]['translation_text']

def get_news_finnhub():
    url = f"https://finnhub.io/api/v1/news?category=general&token={FINNHUB_API_KEY}"
    response = requests.get(url)
    if response.status_code != 200:
        st.error("Erreur lors de la r√©cup√©ration des news Finnhub")
        return []
    news = response.json()
    return news

def get_news_marketaux():
    url = f"https://api.marketaux.com/v1/news/all?api_token={MARKETAUX_API_KEY}&language=en"
    response = requests.get(url)
    if response.status_code != 200:
        st.error("Erreur lors de la r√©cup√©ration des news Marketaux")
        return []
    data = response.json()
    return data.get("data", [])

def filter_economic_news(news_list):
    filtered = []
    for news in news_list:
        # Chercher mots cl√©s dans titre ou description (en minuscule)
        title = news.get("headline") or news.get("title") or ""
        description = news.get("summary") or news.get("description") or ""
        text_to_check = (title + " " + description).lower()
        if any(keyword in text_to_check for keyword in KEYWORDS_ECO):
            filtered.append(news)
    return filtered

def analyze_sentiment(text):
    # Le pipeline renvoie une liste [{'label':..., 'score':...}]
    results = sentiment_analyzer(text)
    labels = {"POSITIVE": "POSITIVE", "NEGATIVE": "NEGATIVE", "NEUTRAL": "NEUTRE"}
    label = results[0]["label"]
    score = results[0]["score"] * 100
    return labels.get(label, label), score

def main():
    st.title("üåç Dashboard √âconomie Mondiale - PRO (Gratuit)")
    st.markdown("News + Indicateurs + Analyse IA + Graphiques + Pr√©visions")

    with st.spinner("R√©cup√©ration des actualit√©s..."):
        news_finnhub = get_news_finnhub()
        news_marketaux = get_news_marketaux()

    news_all = news_finnhub + news_marketaux
    news_filtered = filter_economic_news(news_all)

    st.header("üì∞ Derni√®res actualit√©s √©conomiques filtr√©es")

    if not news_filtered:
        st.info("Aucune actualit√© √©conomique r√©cente trouv√©e.")
        return

    for news in news_filtered[:10]:  # limite √† 10 articles
        title_en = news.get("headline") or news.get("title") or "Sans titre"
        url = news.get("url") or news.get("link") or "#"
        description_en = news.get("summary") or news.get("description") or ""

        # Traduction titre et description
        title_fr = translate_text(title_en)
        description_fr = translate_text(description_en) if description_en else ""

        # R√©sum√© IA (en anglais avant traduction)
        summary_en = summarizer(description_en, max_length=130, min_length=30, do_sample=False)[0]["summary_text"] if description_en else "R√©sum√© non disponible"
        summary_fr = translate_text(summary_en)

        # Analyse sentiment sur r√©sum√© anglais (plus fiable en anglais)
        sentiment_label, sentiment_score = analyze_sentiment(summary_en)

        # Affichage
        st.markdown(f"### [{title_fr}]({url})")
        st.markdown(f"**R√©sum√© IA :** {summary_fr}")
        st.markdown(f"**Sentiment :** {sentiment_label} ({sentiment_score:.2f}%)")
        st.markdown("---")

        # Petit d√©lai pour √©viter surcharge API mod√®les locaux
        time.sleep(0.5)

if __name__ == "__main__":
    main()
